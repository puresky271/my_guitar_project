import numpy as np
import mido
import io
import wave
from numba import jit
from scipy import signal

SR = 48000


@jit(nopython=True, fastmath=True)
def karplus_strong_hifi(n_samples, delay_samples, velocity, brightness, decay_factor):
    """
    é«˜ä¿çœŸ Karplus-Strong ç®—æ³•ï¼ˆç»ˆæç‰ˆï¼‰
    
    æ–°å¢ï¼š
    1. å¼¦å¼ åŠ›éçº¿æ€§ï¼ˆå¤§æŒ¯å¹…æ—¶é¢‘ç‡ä¸Šæ‰¬ï¼‰
    2. æ›´çœŸå®çš„æ¿€åŠ±ä¿¡å·ï¼ˆä¸‰è§’å½¢è€Œéå™ªå£°ï¼‰
    3. åŠ¨æ€é˜»å°¼ï¼ˆæŒ¯å¹…å¤§æ—¶é˜»å°¼å¤§ï¼‰
    """
    output = np.zeros(n_samples, dtype=np.float32)
    
    # === 1. æ¿€åŠ±ä¿¡å·ç”Ÿæˆï¼ˆæ”¹è¿›çš„ä¸‰è§’æ³¢ + å™ªå£°æ··åˆï¼‰===
    burst_len = delay_samples
    if burst_len > n_samples:
        burst_len = n_samples
    
    # ä½¿ç”¨ä¸‰è§’æ³¢è€Œéçº¯å™ªå£°ï¼ˆæ›´æ¥è¿‘çœŸå®æ‹¨å¼¦ï¼‰
    for i in range(burst_len):
        # ä¸‰è§’æ³¢å½¢çŠ¶
        if i < burst_len // 2:
            triangle = (i / (burst_len // 2)) * 2.0 - 1.0
        else:
            triangle = 1.0 - ((i - burst_len // 2) / (burst_len // 2)) * 2.0
        
        # æ··åˆå°‘é‡å™ªå£°
        noise = np.random.uniform(-0.2, 0.2)
        
        # çª—å£å‡½æ•°
        if i < burst_len // 4:
            window = i / (burst_len // 4)
        elif i > 3 * burst_len // 4:
            window = (burst_len - i) / (burst_len // 4)
        else:
            window = 1.0
        
        # äº®åº¦æ§åˆ¶ï¼ˆé«˜ brightness = ä¿ç•™æ›´å¤šé«˜é¢‘ï¼‰
        if i > 0:
            smoothed = triangle * brightness + output[i-1] * (1.0 - brightness) * 0.2
        else:
            smoothed = triangle
        
        output[i] = (smoothed * 0.8 + noise * 0.2) * window * velocity
    
    # === 2. ç‰©ç†åé¦ˆå¾ªç¯ï¼ˆåŠ å…¥éçº¿æ€§ï¼‰===
    freq = SR / delay_samples
    
    # åŸºç¡€è¡°å‡
    base_decay = 0.9992
    freq_decay = min(freq / 1200.0, 1.0) * 0.0008
    user_decay = decay_factor * 0.002
    final_decay = base_decay - freq_decay - user_decay
    final_decay = max(final_decay, 0.988)
    final_decay = min(final_decay, 0.9995)
    
    # ä½é€šæ»¤æ³¢å™¨ç³»æ•°
    alpha = 0.5 + brightness * 0.35
    
    # ä¸»å¾ªç¯ï¼ˆåŠ å…¥éçº¿æ€§æ•ˆæœï¼‰
    for i in range(delay_samples, n_samples):
        delayed_1 = output[i - delay_samples]
        delayed_2 = output[i - delay_samples - 1] if i > delay_samples else 0.0
        
        # ä½é€šæ»¤æ³¢
        filtered = delayed_1 * alpha + delayed_2 * (1.0 - alpha)
        
        # å¼¦å¼ åŠ›éçº¿æ€§ï¼šå¤§æŒ¯å¹…æ—¶äº§ç”Ÿè½»å¾®çš„é¢‘ç‡ä¸Šæ‰¬ï¼ˆç±»ä¼¼çœŸå®å‰ä»–ï¼‰
        amplitude = abs(filtered)
        if amplitude > 0.3:
            tension_factor = 1.0 + (amplitude - 0.3) * 0.02
            filtered *= tension_factor
        
        # åŠ¨æ€é˜»å°¼ï¼šæŒ¯å¹…è¶Šå¤§ï¼Œé˜»å°¼è¶Šå¤§ï¼ˆèƒ½é‡å®ˆæ’ï¼‰
        dynamic_decay = final_decay * (1.0 - amplitude * 0.01)
        
        output[i] = filtered * dynamic_decay
    
    return output


@jit(nopython=True, fastmath=True)
def soft_clipper(x, threshold=0.8):
    """
    å¹³æ»‘è½¯å‰Šæ³¢å™¨ï¼ˆæ¯” tanh æ›´æ¸©å’Œï¼‰
    
    ä½¿ç”¨åˆ†æ®µå‡½æ•°ï¼š
    - |x| < threshold: çº¿æ€§é€šè¿‡
    - |x| >= threshold: ä¸‰æ¬¡å‡½æ•°å¹³æ»‘é™åˆ¶
    """
    if abs(x) < threshold:
        return x
    else:
        sign = 1.0 if x > 0 else -1.0
        excess = abs(x) - threshold
        # ä¸‰æ¬¡æ›²çº¿å¹³æ»‘è¿‡æ¸¡åˆ° 1.0
        clipped = threshold + excess / (1.0 + excess * excess)
        return sign * clipped


def adaptive_limiter(buffer, target_peak=0.95):
    """
    è‡ªé€‚åº”é™åˆ¶å™¨ï¼ˆLook-aheadï¼‰
    
    å…³é”®ï¼šæå‰æ£€æµ‹å³°å€¼ï¼Œå¹³æ»‘é™ä½å¢ç›Šï¼Œé¿å…ç¡¬å‰Šæ³¢
    """
    # è®¡ç®—åŒ…ç»œï¼ˆRMSï¼‰
    window_size = 2048
    rms = np.sqrt(np.convolve(buffer**2, np.ones(window_size)/window_size, mode='same'))
    
    # å³°å€¼æ£€æµ‹
    peak = np.max(np.abs(buffer))
    
    if peak > target_peak:
        # è®¡ç®—å¢ç›Šå‰Šå‡
        gain_reduction = target_peak / peak
        
        # å¹³æ»‘åº”ç”¨å¢ç›Šï¼ˆé¿å…çªå˜ï¼‰
        buffer = buffer * gain_reduction
    
    # è½¯å‰Šæ³¢ä½œä¸ºæœ€åé˜²çº¿
    for i in range(len(buffer)):
        buffer[i] = soft_clipper(buffer[i], target_peak)
    
    return buffer


def spectral_balance_eq(audio_buffer):
    """
    é¢‘è°±å¹³è¡¡å‡è¡¡å™¨ï¼ˆç»ˆæç‰ˆï¼‰
    
    æ–°å¢ï¼š
    1. æ‹¾éŸ³å™¨å…±æŒ¯å³°æ¨¡æ‹Ÿï¼ˆ2-3kHzï¼‰
    2. æ›´å¹³æ»‘çš„é«˜é¢‘æ»šé™
    3. åŠ¨æ€ä½é¢‘æ§åˆ¶
    """
    # 1. é«˜é€šæ»¤æ³¢ï¼šåˆ‡é™¤ 80Hz ä»¥ä¸‹ï¼ˆæ›´é™¡å³­ï¼‰
    sos_hp = signal.butter(6, 80, 'hp', fs=SR, output='sos')  # ä»4é˜¶æå‡åˆ°6é˜¶
    audio_buffer = signal.sosfilt(sos_hp, audio_buffer)
    
    # 2. ä¸­ä½é¢‘æ§åˆ¶ï¼ˆ200-400Hzï¼‰- å‡å°‘"ç®±ä½“è½°é¸£"
    b_notch, a_notch = signal.iirnotch(280, 25, SR)
    notch_signal = signal.lfilter(b_notch, a_notch, audio_buffer)
    audio_buffer = audio_buffer * 0.8 + notch_signal * 0.2
    
    # 3. æ‹¾éŸ³å™¨å…±æŒ¯å³°ï¼ˆ2-3kHzï¼‰- å‰ä»–ç‰¹æœ‰çš„"é‡‘å±è´¨æ„Ÿ"
    b_pickup, a_pickup = signal.iirpeak(2500, 12, SR)
    pickup_resonance = signal.lfilter(b_pickup, a_pickup, audio_buffer) * 0.25
    audio_buffer = audio_buffer + pickup_resonance
    
    # 4. ä¸´åœºæ„Ÿæå‡ï¼ˆ4-5kHzï¼‰
    b_presence, a_presence = signal.iirpeak(4500, 20, SR)
    presence = signal.lfilter(b_presence, a_presence, audio_buffer) * 0.18
    audio_buffer = audio_buffer + presence
    
    # 5. ç©ºæ°”æ„Ÿï¼ˆ8kHz æ¶å­æå‡ï¼‰
    sos_air = signal.butter(1, 8000, 'hp', fs=SR, output='sos')
    air = signal.sosfilt(sos_air, audio_buffer) * 0.12
    audio_buffer = audio_buffer + air
    
    # 6. é«˜é¢‘æŸ”åŒ–ï¼ˆ12kHz å¹³æ»‘æ»šé™ï¼‰
    sos_lp = signal.butter(3, 12000, 'lp', fs=SR, output='sos')  # ä»2é˜¶æå‡åˆ°3é˜¶
    audio_buffer = signal.sosfilt(sos_lp, audio_buffer)
    
    return audio_buffer


def midi_to_audio(midi_stream, brightness, pluck_position, body_mix, reflection, coupling):
    try:
        mid = mido.MidiFile(file=midi_stream)
    except Exception as e:
        print(f"MIDI è§£æå¤±è´¥: {e}")
        return None, None
    
    # é¢„è®¡ç®—æ€»æ—¶é•¿
    total_len = sum(msg.time for msg in mid) + 3.0
    total_samples = int(total_len * SR)
    if total_samples > SR * 300:
        total_samples = SR * 300
    
    mix_buffer = np.zeros(total_samples, dtype=np.float32)
    
    # === MIDI äº‹ä»¶è§£æ ===
    events = []
    cursor = 0
    active_notes = {}
    
    for msg in mid:
        cursor += int(msg.time * SR)
        if msg.type == 'note_on' and msg.velocity > 0:
            active_notes[msg.note] = (cursor, msg.velocity)
        elif (msg.type == 'note_off') or (msg.type == 'note_on' and msg.velocity == 0):
            if msg.note in active_notes:
                start, vel = active_notes.pop(msg.note)
                events.append((start, cursor, msg.note, vel))
    
    # æœªå…³é—­çš„éŸ³ç¬¦
    for note, (start, vel) in active_notes.items():
        events.append((start, total_samples - SR, note, vel))
    
    print(f"ğŸ¸ å‰ä»–å¼•æ“ï¼šå¤„ç† {len(events)} ä¸ªéŸ³ç¬¦äº‹ä»¶")
    
    # === å…³é”®ï¼šåŠ¨æ€èŒƒå›´å‹ç¼©é¢„ç®— ===
    # ç»Ÿè®¡åŒæ—¶å‘å£°çš„æœ€å¤§éŸ³ç¬¦æ•°ï¼Œç”¨äºè‡ªåŠ¨å¢ç›Šæ§åˆ¶
    max_polyphony = 1
    time_grid = np.zeros(total_samples, dtype=np.int16)
    for start, end, note, vel in events:
        if start < total_samples and end > start:
            end = min(end, total_samples)
            time_grid[start:end] += 1
            max_polyphony = max(max_polyphony, np.max(time_grid[start:end]))
    
    # è‡ªåŠ¨å¢ç›Šæ§åˆ¶å› å­
    agc_factor = 1.0 / np.sqrt(max_polyphony)
    print(f"   æœ€å¤§å¤éŸ³æ•°: {max_polyphony}, è‡ªåŠ¨å¢ç›Š: {agc_factor:.3f}")
    
    # === éŸ³ç¬¦æ¸²æŸ“ ===
    for start, end, note, velocity in events:
        if start >= total_samples:
            continue
        
        freq = 440.0 * (2.0 ** ((note - 69) / 12.0))
        if freq > SR / 2 or freq < 30:
            continue
        
        delay_samples = int(SR / freq)
        if delay_samples < 2:
            continue
        
        # === æ”¹è¿›çš„éŸ³é‡æ›²çº¿ ===
        # 1. åŠ›åº¦å“åº”ï¼ˆæ¥è¿‘çœŸå®å‰ä»–ï¼‰
        vel_curve = (velocity / 127.0) ** 1.8  # 1.8 æ¬¡æ–¹æ›´è‡ªç„¶
        
        # 2. é¢‘ç‡å¹³è¡¡ï¼ˆå¤§å¹…å‰Šå‡ä½éŸ³ï¼Œæ¶ˆé™¤é‡‘å±åˆºè€³å£°ï¼‰
        if freq < 150:
            freq_gain = 0.25  # æä½éŸ³å¤§å¹…å‰Šå‡ï¼ˆæ¶ˆé™¤åˆºè€³ï¼‰
        elif freq < 250:
            freq_gain = 0.4   # ä½éŸ³å¤§å¹…è¡°å‡
        elif freq < 500:
            freq_gain = 0.65  # ä¸­ä½éŸ³é€‚åº¦è¡°å‡
        else:
            freq_gain = 1.0   # é«˜éŸ³ä¿æŒ
        
        # 3. è‡ªåŠ¨å¢ç›Šè¡¥å¿
        final_velocity = vel_curve * freq_gain * agc_factor * 0.8
        
        # ç”ŸæˆéŸ³ç¬¦
        duration = (end - start) + int(SR * 0.5)  # ç•™ 0.5 ç§’ä½™éŸ³
        duration = min(duration, total_samples - start)
        
        wave_snippet = karplus_strong_hifi(
            duration, 
            delay_samples, 
            final_velocity, 
            brightness,
            coupling
        )
        
        # === é‡Šæ”¾åŒ…ç»œï¼ˆADSR çš„ Rï¼‰ ===
        release_time = int(SR * 0.15)
        note_off = end - start
        
        if note_off > 0 and note_off < len(wave_snippet):
            if note_off + release_time < len(wave_snippet):
                # å¹³æ»‘é‡Šæ”¾
                fade = np.linspace(1.0, 0.0, release_time)
                wave_snippet[note_off:note_off+release_time] *= fade
                wave_snippet[note_off+release_time:] = 0.0
        
        # å åŠ åˆ°æ··éŸ³ç¼“å†²
        end_idx = min(start + len(wave_snippet), total_samples)
        mix_buffer[start:end_idx] += wave_snippet[:end_idx-start]
    
    # === åå¤„ç†é“¾ ===
    print("   åº”ç”¨åå¤„ç†...")
    
    # 1. é¢‘è°±å¹³è¡¡
    mix_buffer = spectral_balance_eq(mix_buffer)
    
    # 2. ç©ºé—´æ··å“
    if reflection > 0.01:
        delay_samples = int(SR * 0.08)
        if len(mix_buffer) > delay_samples:
            # å¤šé‡å»¶è¿Ÿçº¿ï¼ˆæ›´ä¸°å¯Œçš„æ··å“ï¼‰
            reverb = np.zeros_like(mix_buffer)
            reverb[delay_samples:] += mix_buffer[:-delay_samples] * reflection * 0.5
            
            delay2 = int(SR * 0.12)
            if len(mix_buffer) > delay2:
                reverb[delay2:] += mix_buffer[:-delay2] * reflection * 0.3
            
            mix_buffer = mix_buffer * 0.8 + reverb * 0.2
    
    # 3. è‡ªé€‚åº”é™åˆ¶å™¨
    mix_buffer = adaptive_limiter(mix_buffer, target_peak=0.93)
    
    # 4. æœ€ç»ˆå½’ä¸€åŒ–
    peak = np.max(np.abs(mix_buffer))
    if peak > 0.01:
        mix_buffer = mix_buffer / peak * 0.95
    
    # è½¬æ¢ä¸º WAV
    samples_int = (mix_buffer * 32767).astype(np.int16)
    
    buf = io.BytesIO()
    try:
        with wave.open(buf, 'wb') as wf:
            wf.setnchannels(1)
            wf.setsampwidth(2)
            wf.setframerate(SR)
            wf.writeframes(samples_int.tobytes())
    except Exception as e:
        print(f"WAV å†™å…¥å¤±è´¥: {e}")
        return None, None
    
    print("âœ… å‰ä»–æ¸²æŸ“å®Œæˆ")
    return buf.getvalue(), mix_buffer
