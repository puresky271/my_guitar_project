import numpy as np
import mido
import io
import wave
from numba import jit
from scipy import signal

SR = 48000


@jit(nopython=True, fastmath=True)
def karplus_strong_hifi(n_samples, delay_samples, velocity, brightness, decay_factor):
    """
    é«˜ä¿çœŸ Karplus-Strong ç®—æ³•

    å…³é”®æ”¹è¿›ï¼š
    1. å¹³æ»‘çš„æ¿€åŠ±ä¿¡å·ï¼ˆé¿å…å°–é”çš„ç‚¹å‡»å£°ï¼‰
    2. é¢‘ç‡è‡ªé€‚åº”çš„ä½é€šæ»¤æ³¢
    3. æ¸è¿›å¼èƒ½é‡è¡°å‡ï¼ˆé¿å…çªç„¶æˆªæ­¢ï¼‰
    """
    output = np.zeros(n_samples, dtype=np.float32)

    # === 1. æ¿€åŠ±ä¿¡å·ç”Ÿæˆ ===
    # ä½¿ç”¨å¸¦é™å™ªå£°ï¼Œé¿å…é«˜é¢‘å•¸å«
    burst_len = delay_samples
    if burst_len > n_samples:
        burst_len = n_samples

    # ä¸‰è§’æ»¤æ³¢çª—å£ï¼Œå¹³æ»‘æ¿€åŠ±
    for i in range(burst_len):
        # ç™½å™ªå£°
        noise = np.random.uniform(-0.5, 0.5)

        # ä¸‰è§’çª—å£ï¼ˆæ¸å…¥æ¸å‡ºï¼‰
        if i < burst_len // 3:
            window = i / (burst_len // 3)
        elif i > 2 * burst_len // 3:
            window = (burst_len - i) / (burst_len // 3)
        else:
            window = 1.0

        # æ··åˆäº®åº¦ï¼šé«˜ brightness = ä¿ç•™æ›´å¤šé«˜é¢‘
        if i > 0:
            smoothed = noise * brightness + output[i - 1] * (1.0 - brightness) * 0.3
        else:
            smoothed = noise

        output[i] = smoothed * window * velocity

    # === 2. ç‰©ç†åé¦ˆå¾ªç¯ ===
    # é¢‘ç‡è‡ªé€‚åº”è¡°å‡ï¼šä½éŸ³è¡°å‡æ…¢ï¼Œé«˜éŸ³è¡°å‡å¿«
    freq = SR / delay_samples

    # åŸºç¡€è¡°å‡ï¼ˆé«˜ä¿çœŸï¼‰
    base_decay = 0.9990

    # é¢‘ç‡ç›¸å…³çš„é¢å¤–è¡°å‡
    freq_decay = min(freq / 1000.0, 1.0) * 0.001

    # ç”¨æˆ·å¯æ§çš„è¡°å‡å› å­
    user_decay = decay_factor * 0.002

    final_decay = base_decay - freq_decay - user_decay
    final_decay = max(final_decay, 0.985)  # é˜²æ­¢è¿‡å¿«è¡°å‡
    final_decay = min(final_decay, 0.999)  # é˜²æ­¢ä¸è¡°å‡

    # ä½é€šæ»¤æ³¢å™¨ç³»æ•°ï¼ˆKarplus-Strong æ ¸å¿ƒï¼‰
    # brightness æ§åˆ¶é«˜é¢‘ä¿ç•™
    alpha = 0.5 + brightness * 0.3

    # ä¸»å¾ªç¯
    for i in range(delay_samples, n_samples):
        # å»¶è¿Ÿçº¿è¯»å–
        delayed_1 = output[i - delay_samples]
        delayed_2 = output[i - delay_samples - 1] if i > delay_samples else 0.0

        # ä½é€šæ»¤æ³¢ï¼ˆå¹³æ»‘ï¼‰
        filtered = delayed_1 * alpha + delayed_2 * (1.0 - alpha)

        # åº”ç”¨è¡°å‡
        output[i] = filtered * final_decay

    return output


@jit(nopython=True, fastmath=True)
def soft_clipper(x, threshold=0.8):
    """
    å¹³æ»‘è½¯å‰Šæ³¢å™¨ï¼ˆæ¯” tanh æ›´æ¸©å’Œï¼‰

    ä½¿ç”¨åˆ†æ®µå‡½æ•°ï¼š
    - |x| < threshold: çº¿æ€§é€šè¿‡
    - |x| >= threshold: ä¸‰æ¬¡å‡½æ•°å¹³æ»‘é™åˆ¶
    """
    if abs(x) < threshold:
        return x
    else:
        sign = 1.0 if x > 0 else -1.0
        excess = abs(x) - threshold
        # ä¸‰æ¬¡æ›²çº¿å¹³æ»‘è¿‡æ¸¡åˆ° 1.0
        clipped = threshold + excess / (1.0 + excess * excess)
        return sign * clipped


def adaptive_limiter(buffer, target_peak=0.95):
    """
    è‡ªé€‚åº”é™åˆ¶å™¨ï¼ˆLook-aheadï¼‰

    å…³é”®ï¼šæå‰æ£€æµ‹å³°å€¼ï¼Œå¹³æ»‘é™ä½å¢ç›Šï¼Œé¿å…ç¡¬å‰Šæ³¢
    """
    # è®¡ç®—åŒ…ç»œï¼ˆRMSï¼‰
    window_size = 2048
    rms = np.sqrt(np.convolve(buffer ** 2, np.ones(window_size) / window_size, mode='same'))

    # å³°å€¼æ£€æµ‹
    peak = np.max(np.abs(buffer))

    if peak > target_peak:
        # è®¡ç®—å¢ç›Šå‰Šå‡
        gain_reduction = target_peak / peak

        # å¹³æ»‘åº”ç”¨å¢ç›Šï¼ˆé¿å…çªå˜ï¼‰
        buffer = buffer * gain_reduction

    # è½¯å‰Šæ³¢ä½œä¸ºæœ€åé˜²çº¿
    for i in range(len(buffer)):
        buffer[i] = soft_clipper(buffer[i], target_peak)

    return buffer


def spectral_balance_eq(audio_buffer):
    """
    é¢‘è°±å¹³è¡¡å‡è¡¡å™¨

    è§£å†³é—®é¢˜ï¼š
    1. ä½é¢‘è½°é¸£ï¼ˆ< 80Hzï¼‰
    2. æ³¥æ³çš„ä¸­ä½é¢‘ï¼ˆ200-400Hzï¼‰
    3. åˆºè€³çš„é«˜é¢‘ï¼ˆ> 8kHzï¼‰
    """
    # 1. é«˜é€šæ»¤æ³¢ï¼šåˆ‡é™¤ 80Hz ä»¥ä¸‹
    sos_hp = signal.butter(4, 80, 'hp', fs=SR, output='sos')
    audio_buffer = signal.sosfilt(sos_hp, audio_buffer)

    # 2. ä¸­ä½é¢‘è½»å¾®è¡°å‡ï¼ˆå‡å°‘"ç®±ä½“æ„Ÿ"ï¼‰
    # ä½¿ç”¨é™·æ³¢æ»¤æ³¢å™¨åœ¨ 300Hz
    b_notch, a_notch = signal.iirnotch(300, 30, SR)
    notch_signal = signal.lfilter(b_notch, a_notch, audio_buffer)
    audio_buffer = audio_buffer * 0.85 + notch_signal * 0.15

    # 3. ä¸´åœºæ„Ÿæå‡ï¼š3-5kHz è½»å¾®æå‡
    b_peak, a_peak = signal.iirpeak(4000, 30, SR)
    presence = signal.lfilter(b_peak, a_peak, audio_buffer) * 0.15
    audio_buffer = audio_buffer + presence

    # 4. é«˜é¢‘æŸ”åŒ–ï¼š8kHz ä»¥ä¸Šè½»å¾®æ»šé™
    sos_lp = signal.butter(2, 10000, 'lp', fs=SR, output='sos')
    audio_buffer = signal.sosfilt(sos_lp, audio_buffer)

    return audio_buffer


def midi_to_audio(midi_stream, brightness, pluck_position, body_mix, reflection, coupling):
    try:
        mid = mido.MidiFile(file=midi_stream)
    except Exception as e:
        print(f"MIDI è§£æå¤±è´¥: {e}")
        return None, None

    # é¢„è®¡ç®—æ€»æ—¶é•¿
    total_len = sum(msg.time for msg in mid) + 3.0
    total_samples = int(total_len * SR)
    if total_samples > SR * 300:
        total_samples = SR * 300

    mix_buffer = np.zeros(total_samples, dtype=np.float32)

    # === MIDI äº‹ä»¶è§£æ ===
    events = []
    cursor = 0
    active_notes = {}

    for msg in mid:
        cursor += int(msg.time * SR)
        if msg.type == 'note_on' and msg.velocity > 0:
            active_notes[msg.note] = (cursor, msg.velocity)
        elif (msg.type == 'note_off') or (msg.type == 'note_on' and msg.velocity == 0):
            if msg.note in active_notes:
                start, vel = active_notes.pop(msg.note)
                events.append((start, cursor, msg.note, vel))

    # æœªå…³é—­çš„éŸ³ç¬¦
    for note, (start, vel) in active_notes.items():
        events.append((start, total_samples - SR, note, vel))

    print(f"ğŸ¸ å‰ä»–å¼•æ“ï¼šå¤„ç† {len(events)} ä¸ªéŸ³ç¬¦äº‹ä»¶")

    # === å…³é”®ï¼šåŠ¨æ€èŒƒå›´å‹ç¼©é¢„ç®— ===
    # ç»Ÿè®¡åŒæ—¶å‘å£°çš„æœ€å¤§éŸ³ç¬¦æ•°ï¼Œç”¨äºè‡ªåŠ¨å¢ç›Šæ§åˆ¶
    max_polyphony = 1
    time_grid = np.zeros(total_samples, dtype=np.int16)
    for start, end, note, vel in events:
        if start < total_samples and end > start:
            end = min(end, total_samples)
            time_grid[start:end] += 1
            max_polyphony = max(max_polyphony, np.max(time_grid[start:end]))

    # è‡ªåŠ¨å¢ç›Šæ§åˆ¶å› å­
    agc_factor = 1.0 / np.sqrt(max_polyphony)
    print(f"   æœ€å¤§å¤éŸ³æ•°: {max_polyphony}, è‡ªåŠ¨å¢ç›Š: {agc_factor:.3f}")

    # === éŸ³ç¬¦æ¸²æŸ“ ===
    for start, end, note, velocity in events:
        if start >= total_samples:
            continue

        freq = 440.0 * (2.0 ** ((note - 69) / 12.0))
        if freq > SR / 2 or freq < 30:
            continue

        delay_samples = int(SR / freq)
        if delay_samples < 2:
            continue

        # === æ”¹è¿›çš„éŸ³é‡æ›²çº¿ ===
        # 1. åŠ›åº¦å“åº”ï¼ˆæ¥è¿‘çœŸå®å‰ä»–ï¼‰
        vel_curve = (velocity / 127.0) ** 1.8  # 1.8 æ¬¡æ–¹æ›´è‡ªç„¶

        # 2. é¢‘ç‡å¹³è¡¡ï¼ˆå¤§å¹…å‰Šå‡ä½éŸ³ï¼Œæ¶ˆé™¤é‡‘å±åˆºè€³å£°ï¼‰
        if freq < 150:
            freq_gain = 0.00  # æä½éŸ³ï¼ˆæ¶ˆé™¤åˆºè€³ï¼‰
        elif freq < 250:
            freq_gain = 0.25  # ä½éŸ³å¤§å¹…è¡°å‡
        elif freq < 500:
            freq_gain = 0.65  # ä¸­ä½éŸ³é€‚åº¦è¡°å‡
        else:
            freq_gain = 1.0  # é«˜éŸ³ä¿æŒ

        # 3. è‡ªåŠ¨å¢ç›Šè¡¥å¿
        final_velocity = vel_curve * freq_gain * agc_factor * 0.8

        # ç”ŸæˆéŸ³ç¬¦
        duration = (end - start) + int(SR * 0.5)  # ç•™ 0.5 ç§’ä½™éŸ³
        duration = min(duration, total_samples - start)

        wave_snippet = karplus_strong_hifi(
            duration,
            delay_samples,
            final_velocity,
            brightness,
            coupling
        )

        # === é‡Šæ”¾åŒ…ç»œï¼ˆADSR çš„ Rï¼‰ ===
        release_time = int(SR * 0.15)
        note_off = end - start

        if note_off > 0 and note_off < len(wave_snippet):
            if note_off + release_time < len(wave_snippet):
                # å¹³æ»‘é‡Šæ”¾
                fade = np.linspace(1.0, 0.0, release_time)
                wave_snippet[note_off:note_off + release_time] *= fade
                wave_snippet[note_off + release_time:] = 0.0

        # å åŠ åˆ°æ··éŸ³ç¼“å†²
        end_idx = min(start + len(wave_snippet), total_samples)
        mix_buffer[start:end_idx] += wave_snippet[:end_idx - start]

    # === åå¤„ç†é“¾ ===
    print("   åº”ç”¨åå¤„ç†...")

    # 1. é¢‘è°±å¹³è¡¡
    mix_buffer = spectral_balance_eq(mix_buffer)

    # 2. ç©ºé—´æ··å“
    if reflection > 0.01:
        delay_samples = int(SR * 0.08)
        if len(mix_buffer) > delay_samples:
            # å¤šé‡å»¶è¿Ÿçº¿ï¼ˆæ›´ä¸°å¯Œçš„æ··å“ï¼‰
            reverb = np.zeros_like(mix_buffer)
            reverb[delay_samples:] += mix_buffer[:-delay_samples] * reflection * 0.5

            delay2 = int(SR * 0.12)
            if len(mix_buffer) > delay2:
                reverb[delay2:] += mix_buffer[:-delay2] * reflection * 0.3

            mix_buffer = mix_buffer * 0.8 + reverb * 0.2

    # 3. è‡ªé€‚åº”é™åˆ¶å™¨
    mix_buffer = adaptive_limiter(mix_buffer, target_peak=0.93)

    # 4. æœ€ç»ˆå½’ä¸€åŒ–
    peak = np.max(np.abs(mix_buffer))
    if peak > 0.01:
        mix_buffer = mix_buffer / peak * 0.95

    # è½¬æ¢ä¸º WAV
    samples_int = (mix_buffer * 32767).astype(np.int16)

    buf = io.BytesIO()
    try:
        with wave.open(buf, 'wb') as wf:
            wf.setnchannels(1)
            wf.setsampwidth(2)
            wf.setframerate(SR)
            wf.writeframes(samples_int.tobytes())
    except Exception as e:
        print(f"WAV å†™å…¥å¤±è´¥: {e}")
        return None, None

    print("âœ… å‰ä»–æ¸²æŸ“å®Œæˆ")
    return buf.getvalue(), mix_buffer

