import numpy as np
import mido
import io
import wave
from numba import jit
from scipy import signal

SR = 48000


@jit(nopython=True, fastmath=True)
def bass_string_model(n_samples, delay_samples, velocity, brightness):
    """
    è´æ–¯å¼¦ç‰©ç†æ¨¡å‹

    è´æ–¯ç‰¹ç‚¹ï¼š
    1. å¼¦æ›´ç²—æ›´é‡ â†’ è¡°å‡ææ…¢
    2. å¼ åŠ›æ›´ä½ â†’ æ›´å¤šéçº¿æ€§
    3. ä½é¢‘ä¸°å¯Œ â†’ éœ€è¦ç‰¹æ®Šå¤„ç†
    """
    output = np.zeros(n_samples, dtype=np.float32)

    # === 1. æ¿€åŠ±ä¿¡å·ï¼ˆè´æ–¯çš„æ‹¨å¼¦æ›´"è‚‰"ï¼‰ ===
    burst_len = int(delay_samples * 1.2)  # è´æ–¯æ¿€åŠ±æ›´é•¿
    if burst_len > n_samples:
        burst_len = n_samples
    
    # [BUGFIX] é˜²æ­¢ burst_len è¿‡å°æ—¶é™¤ä»¥ 0
    rise_len = burst_len // 4
    if rise_len < 1:
        rise_len = 1

    # ä½¿ç”¨æ›´åšé‡çš„æ¿€åŠ±æ³¢å½¢
    for i in range(burst_len):
        # æ¢¯å½¢æ³¢ï¼ˆè€Œéä¸‰è§’æ³¢ï¼‰ï¼Œæ›´"åšå®"
        if i < rise_len:
            shape = i / rise_len
        elif i < 3 * rise_len:
            shape = 1.0
        else:
            # è¿™é‡Œçš„é€»è¾‘ä¹Ÿéœ€è¦é€‚é… rise_len ä»¥é˜²è¶Šç•Œï¼Œä½†åœ¨ Numba ä¸­é€šå¸¸ ok
            # ç®€å•ä¿®æ”¹ä¸ºåŸºäº rise_len çš„ä¸‹é™
            fall_phase = i - 3 * rise_len
            shape = 1.0 - (fall_phase / rise_len)
            if shape < 0: shape = 0.0

        # å°‘é‡å™ªå£°
        noise = np.random.uniform(-0.15, 0.15)

        # ä½é€šå¹³æ»‘ï¼ˆè´æ–¯é«˜é¢‘å°‘ï¼‰
        if i > 0:
            smoothed = shape * 0.7 + output[i - 1] * 0.3
        else:
            smoothed = shape

        output[i] = (smoothed * 0.85 + noise * 0.15) * velocity

    # === 2. ç‰©ç†åé¦ˆå¾ªç¯ï¼ˆè´æ–¯è¡°å‡ææ…¢ï¼‰ ===
    freq = SR / delay_samples

    # è´æ–¯çš„è¡°å‡æ¯”å‰ä»–æ…¢å¾—å¤š
    base_decay = 0.9996  # å‰ä»–æ˜¯ 0.9992

    # ä½é¢‘é¢å¤–ä¿æŠ¤ï¼ˆè´æ–¯æœ€é‡è¦çš„æ˜¯ä½é¢‘æŒç»­ï¼‰
    if freq < 100:
        base_decay = 0.9998
    elif freq < 200:
        base_decay = 0.9997

    # è´æ–¯çš„ä½é€šæ»¤æ³¢æ›´æ¿€è¿›ï¼ˆå¤©ç„¶é«˜é¢‘å°‘ï¼‰
    alpha = 0.4 + brightness * 0.25  # æ¯”å‰ä»–æ›´ä½

    # ä¸»å¾ªç¯ï¼ˆåŠ å…¥è´æ–¯ç‰¹æœ‰çš„"æ¾å¼›"éçº¿æ€§ï¼‰
    for i in range(delay_samples, n_samples):
        delayed_1 = output[i - delay_samples]
        delayed_2 = output[i - delay_samples - 1] if i > delay_samples else 0.0

        # ä½é€šæ»¤æ³¢
        filtered = delayed_1 * alpha + delayed_2 * (1.0 - alpha)

        # è´æ–¯å¼¦çš„"æ¾å¼›"éçº¿æ€§ï¼šä½å¼ åŠ›å¯¼è‡´çš„é¢‘ç‡ä¸‹æ¢
        amplitude = abs(filtered)
        if amplitude > 0.2:
            # å¤§æŒ¯å¹…æ—¶é¢‘ç‡ç•¥å¾®ä¸‹é™ï¼ˆä¸å‰ä»–ç›¸åï¼‰
            tension_sag = 1.0 - (amplitude - 0.2) * 0.015
            filtered *= tension_sag

        output[i] = filtered * base_decay

    return output


def bass_body_filter(samples, mix):
    """
    è´æ–¯ç®±ä½“å…±é¸£ï¼ˆä¸å‰ä»–ä¸åŒï¼‰

    è´æ–¯ç‰¹ç‚¹ï¼š
    - ä¸»å…±æŒ¯åœ¨ 80-120Hzï¼ˆæ›´ä½ï¼‰
    - Q å€¼æ›´é«˜ï¼ˆæ›´çª„çš„å³°ï¼‰
    """
    if mix <= 0:
        return samples

    # ä¸»å…±æŒ¯å³°åœ¨ 100Hz
    b_body, a_body = signal.iirpeak(100, 8, SR)
    body_resonance = signal.lfilter(b_body, a_body, samples)

    # æ¬¡å…±æŒ¯å³°åœ¨ 180Hz
    b_body2, a_body2 = signal.iirpeak(180, 12, SR)
    body_resonance2 = signal.lfilter(b_body2, a_body2, samples)

    # æ··åˆ
    result = samples * (1 - mix) + (body_resonance * 0.6 + body_resonance2 * 0.4) * mix

    return result


def bass_eq_mastering(audio_buffer):
    """
    è´æ–¯ä¸“ç”¨ EQ

    ç›®æ ‡ï¼š
    1. ä¿ç•™ 40-150Hz çš„æ ¸å¿ƒä½é¢‘
    2. å‰Šå‡ 200-500Hz çš„"æ³¥æ³"
    3. æå‡ 2-4kHz çš„"é¢—ç²’æ„Ÿ"ï¼ˆæ‹¨å¼¦å£°ï¼‰
    """
    # 1. é«˜é€š 30Hzï¼ˆåªåˆ‡æœ€ä½çš„éš†éš†å£°ï¼‰
    sos_hp = signal.butter(4, 30, 'hp', fs=SR, output='sos')
    audio_buffer = signal.sosfilt(sos_hp, audio_buffer)

    # 2. ä½é¢‘æ ¸å¿ƒæå‡ï¼ˆ80Hzï¼‰
    b_low, a_low = signal.iirpeak(80, 6, SR)
    low_boost = signal.lfilter(b_low, a_low, audio_buffer) * 0.2
    audio_buffer = audio_buffer + low_boost

    # 3. ä¸­ä½é¢‘å‰Šå‡ï¼ˆ250-400Hzï¼Œæ¶ˆé™¤"æ³¥æ³"ï¼‰
    b_mud, a_mud = signal.iirnotch(320, 10, SR)
    audio_buffer = signal.lfilter(b_mud, a_mud, audio_buffer)

    # 4. é«˜ä¸­é¢‘æå‡ï¼ˆ2.5kHzï¼Œæ‹¨å¼¦"é¢—ç²’æ„Ÿ"ï¼‰
    b_attack, a_attack = signal.iirpeak(2500, 15, SR)
    attack_boost = signal.lfilter(b_attack, a_attack, audio_buffer) * 0.25
    audio_buffer = audio_buffer + attack_boost

    # 5. é«˜é¢‘é€‚åº¦æ»šé™ï¼ˆè´æ–¯ä¸éœ€è¦å¤ªå¤šé«˜é¢‘ï¼‰
    sos_lp = signal.butter(2, 8000, 'lp', fs=SR, output='sos')
    audio_buffer = signal.sosfilt(sos_lp, audio_buffer)

    return audio_buffer


def adaptive_limiter(buffer, target_peak=0.95):
    """è´æ–¯ä¸“ç”¨é™åˆ¶å™¨ï¼ˆä½é¢‘å‹å¥½ï¼‰"""
    # å¯¹ä½é¢‘æ›´æ¸©å’Œçš„é™åˆ¶
    for i in range(len(buffer)):
        if abs(buffer[i]) > target_peak:
            # è½¯å‰Šæ³¢
            sign = 1.0 if buffer[i] > 0 else -1.0
            excess = abs(buffer[i]) - target_peak
            buffer[i] = sign * (target_peak + excess / (1.0 + excess * 2))

    return buffer


def midi_to_audio(midi_stream, brightness, pluck_position, body_mix, reflection, coupling):
    """
    è´æ–¯ MIDI æ¸²æŸ“

    å‚æ•°æ˜ å°„ï¼š
    - brightness: éŸ³è‰²æ˜äº®åº¦ï¼ˆæ§åˆ¶é«˜é¢‘ï¼‰
    - pluck_position: æ‹¨å¼¦åŠ›åº¦æ›²çº¿
    - body_mix: ç®±ä½“å…±é¸£å¼ºåº¦
    - reflection: æˆ¿é—´æ··å“
    - coupling: æœªä½¿ç”¨ï¼ˆè´æ–¯å•å¼¦ï¼‰
    """
    # æ˜¯å¦å¯ç”¨è´æ–¯è‡ªåŠ¨æ”¹ç¼–ï¼ˆåªå½±å“ Bass ç‹¬å¥ï¼‰
    AUTO_BASS_ARRANGE = True

    try:
        mid = mido.MidiFile(file=midi_stream)
    except Exception as e:
        print(f"MIDI è§£æå¤±è´¥: {e}")
        return None, None

    total_len = sum(msg.time for msg in mid) + 4.0
    total_samples = int(total_len * SR)
    if total_samples > SR * 300:
        total_samples = SR * 300

    mix_buffer = np.zeros(total_samples, dtype=np.float32)

    # MIDI äº‹ä»¶è§£æ
    events = []
    cursor = 0
    active_notes = {}

    for msg in mid:
        cursor += int(msg.time * SR)
        if msg.type == 'note_on' and msg.velocity > 0:
            active_notes[msg.note] = (cursor, msg.velocity)
        elif (msg.type == 'note_off') or (msg.type == 'note_on' and msg.velocity == 0):
            if msg.note in active_notes:
                start, vel = active_notes.pop(msg.note)
                events.append((start, cursor, msg.note, vel))

    for note, (start, vel) in active_notes.items():
        events.append((start, total_samples - SR, note, vel))

    print(f"ğŸ¸ è´æ–¯å¼•æ“ï¼šå¤„ç† {len(events)} ä¸ªéŸ³ç¬¦äº‹ä»¶")

    # è‡ªåŠ¨å¢ç›Šæ§åˆ¶
    max_polyphony = 1
    time_grid = np.zeros(total_samples, dtype=np.int16)
    # [BUGFIX] events è¿™é‡Œæ˜¯ 4 ä¸ªå…ƒç´ ï¼Œä¿®æ­£è§£åŒ…å˜é‡
    for start, end, note, vel in events:
        if start < total_samples and end > start:
            end = min(end, total_samples)
            time_grid[start:end] += 1
            max_polyphony = max(max_polyphony, np.max(time_grid[start:end]))

    agc_factor = 1.0 / np.sqrt(max_polyphony)
    print(f"   æœ€å¤§å¤éŸ³æ•°: {max_polyphony}, è‡ªåŠ¨å¢ç›Š: {agc_factor:.3f}")

    # éŸ³ç¬¦æ¸²æŸ“
    # [BUGFIX] å»æ‰äº† pedï¼Œevents åªæœ‰ 4 ä¸ªå…ƒç´ 
    for start, end, note, velocity in events:

        # ================== Bass è‡ªåŠ¨æ”¹ç¼–æ ¸å¿ƒ ==================
        if AUTO_BASS_ARRANGE:
            # å‹åˆ°è´æ–¯éŸ³åŸŸ E1 ~ G3
            while note > 55:
                note -= 12
            while note < 28:
                note += 12

            # è´æ–¯ä¸æ¼”å’Œå¼¦ï¼Œåªå–ä½éŸ³ï¼ˆå·²ç»æ˜¯æœ€ä½éŸ³åŸŸäº†ï¼‰
            # å¹¶ä¸”å»¶é•¿æ—¶å€¼ï¼Œè®©æ—‹å¾‹è¿è´¯
            end += int(0.15 * SR)
        # ======================================================

        if start >= total_samples:
            continue

        freq = 440.0 * (2.0 ** ((note - 69) / 12.0))

        # è´æ–¯æœ‰æ•ˆéŸ³åŸŸï¼šE1 (41.2Hz) åˆ° C4 (261Hz)
        if freq > 300 or freq < 35:
            continue

        delay_samples = int(SR / freq)
        if delay_samples < 2:
            continue

        # åŠ›åº¦æ›²çº¿ï¼ˆä½¿ç”¨ pluck_position å‚æ•°ï¼‰
        vel_curve = (velocity / 127.0) ** pluck_position

        # è´æ–¯ä¸éœ€è¦é¢‘ç‡å¹³è¡¡ï¼ˆä½é¢‘å°±æ˜¯ä¼˜åŠ¿ï¼‰
        freq_gain = 1.0

        final_velocity = vel_curve * freq_gain * agc_factor * 1.2

        # ç”ŸæˆéŸ³ç¬¦ï¼ˆè´æ–¯ä½™éŸ³æ›´é•¿ï¼‰
        duration = (end - start) + int(SR * 0.8)
        duration = min(duration, total_samples - start)

        wave_snippet = bass_string_model(
            duration,
            delay_samples,
            final_velocity,
            brightness
        )

        # é‡Šæ”¾åŒ…ç»œ
        release_time = int(SR * 0.2)
        note_off = end - start

        if note_off > 0 and note_off < len(wave_snippet):
            if note_off + release_time < len(wave_snippet):
                fade = np.linspace(1.0, 0.0, release_time)
                wave_snippet[note_off:note_off + release_time] *= fade
                wave_snippet[note_off + release_time:] = 0.0

        # å åŠ 
        end_idx = min(start + len(wave_snippet), total_samples)
        # ç¡®ä¿åˆ‡ç‰‡é•¿åº¦ä¸€è‡´
        snippet_len = end_idx - start
        if snippet_len > 0:
            mix_buffer[start:end_idx] += wave_snippet[:snippet_len]

    # åå¤„ç†é“¾
    print("   åº”ç”¨åå¤„ç†...")

    # 1. è´æ–¯ç®±ä½“å…±é¸£
    mix_buffer = bass_body_filter(mix_buffer, body_mix)

    # 2. è´æ–¯ EQ
    mix_buffer = bass_eq_mastering(mix_buffer)

    # 3. æˆ¿é—´æ··å“
    if reflection > 0.01:
        delay_samples = int(SR * 0.06)
        if len(mix_buffer) > delay_samples:
            reverb = np.zeros_like(mix_buffer)
            reverb[delay_samples:] += mix_buffer[:-delay_samples] * reflection * 0.4
            mix_buffer = mix_buffer * 0.85 + reverb * 0.15

    # 4. è‡ªé€‚åº”é™åˆ¶å™¨
    mix_buffer = adaptive_limiter(mix_buffer, target_peak=0.95)

    # 5. æœ€ç»ˆå½’ä¸€åŒ–
    peak = np.max(np.abs(mix_buffer))
    if peak > 0.01:
        mix_buffer = mix_buffer / peak * 0.96

    # è½¬æ¢ä¸º WAV
    samples_int = (mix_buffer * 32767).astype(np.int16)

    buf = io.BytesIO()
    try:
        with wave.open(buf, 'wb') as wf:
            wf.setnchannels(1)
            wf.setsampwidth(2)
            wf.setframerate(SR)
            wf.writeframes(samples_int.tobytes())
    except Exception as e:
        print(f"WAV å†™å…¥å¤±è´¥: {e}")
        return None, None

    print("âœ… è´æ–¯æ¸²æŸ“å®Œæˆ")

    return buf.getvalue(), mix_buffer
