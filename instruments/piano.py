import numpy as np
import mido
import io
import wave
from numba import jit
from scipy import signal

SR = 48000


@jit(nopython=True, fastmath=True)
def piano_string_model(n_samples, frequency, velocity, string_num, total_strings):
    """
    å•æ ¹é’¢ç´å¼¦çš„ç‰©ç†æ¨¡å‹

    å‚æ•°:
    - string_num: å½“å‰æ˜¯ç¬¬å‡ æ ¹å¼¦ï¼ˆ0, 1, 2ï¼‰
    - total_strings: æ€»å…±å‡ æ ¹å¼¦ï¼ˆ1, 2, 3ï¼‰
    """
    delay_samples = int(SR / frequency)
    if delay_samples < 2:
        delay_samples = 2

    output = np.zeros(n_samples, dtype=np.float32)

    # === 1. ç´æ§Œå‡»å¼¦æ¨¡å‹ï¼ˆçœŸå®ç‰©ç†ï¼‰ ===
    # ç´æ§Œæ¥è§¦æ—¶é—´ï¼šçº¦ 1-4msï¼ˆé¢‘ç‡è¶Šé«˜ï¼Œæ¥è§¦æ—¶é—´è¶ŠçŸ­ï¼‰
    contact_time = max(0.001, 0.004 - frequency / 2000.0)
    contact_samples = int(contact_time * SR)

    
    hammer_velocity = velocity

    # å¤šå¼¦ç³»ç»Ÿï¼šæ¯æ ¹å¼¦çš„ç›¸ä½ç•¥æœ‰ä¸åŒ
    phase_offset = string_num * 0.05

    # å‡»å¼¦ä½ç½®ï¼ˆé’¢ç´é€šå¸¸åœ¨å¼¦é•¿çš„ 1/7 åˆ° 1/9 å¤„ï¼‰
    strike_position = 1.0 / 8.0
    strike_delay = int(delay_samples * strike_position)

    # ç”Ÿæˆç´æ§Œè„‰å†²
    for i in range(contact_samples):
        t = i / contact_samples

        # ç´æ§Œå½¢çŠ¶ï¼šå¿«é€Ÿä¸Šå‡ + æ…¢é€Ÿå›è½
        # ä½¿ç”¨ raised cosine å‡½æ•°
        hammer_shape = (1.0 - np.cos(np.pi * t)) / 2.0

        # åº”ç”¨éçº¿æ€§ï¼ˆæ¯›æ¯¡çš„å¼¹æ€§ï¼‰
        hammer_force = hammer_shape * (1.0 - hammer_shape * 0.3)

        output[i] = hammer_force * hammer_velocity

        # åå‘è„‰å†²ï¼ˆåœ¨å‡»å¼¦ç‚¹äº§ç”Ÿï¼‰
        if i + strike_delay < n_samples:
            output[i + strike_delay] -= hammer_force * hammer_velocity * 0.4

    # æ·»åŠ å¾®å°å™ªå£°ï¼ˆç´å¼¦çš„å¾®è§‚ä¸å®Œç¾ï¼‰
    for i in range(min(contact_samples * 2, n_samples)):
        output[i] += np.random.normal(0, 0.002) * velocity

    # === 2. å¼¦çš„ä¼ æ’­å’Œè¡°å‡ ===
    # é’¢ç´å¼¦çš„è¡°å‡éå¸¸å¤æ‚ï¼Œåˆ†ä¸ºä¸‰ä¸ªé˜¶æ®µ

    # åŸºç¡€è¡°å‡ï¼ˆä¸é¢‘ç‡å¼ºç›¸å…³ï¼‰- è°ƒæ•´ä¸ºæ›´æ˜äº®
    if frequency < 100:
        # ä½éŸ³å¼¦ï¼šé•¿ã€ç²—ã€ç¼ ç»•ï¼Œè¡°å‡ææ…¢
        base_decay = 0.9998
    elif frequency < 500:
        # ä¸­éŸ³å¼¦ï¼šä¸­ç­‰è¡°å‡ï¼ˆå¢åŠ äº®åº¦ï¼‰
        base_decay = 0.9997
    else:
        # é«˜éŸ³å¼¦ï¼šçŸ­ã€ç»†ï¼Œä½†ä¸è¦è¡°å‡å¤ªå¿«ï¼ˆä¿æŒæ˜äº®ï¼‰
        base_decay = 0.9995

    # é«˜é¢‘æˆåˆ†è¡°å‡æ›´å¿«ï¼ˆè‰²æ•£æ•ˆåº”ï¼‰- å‡å°‘è¿™ä¸ªæ•ˆåº”ï¼Œä¿æŒæ˜äº®
    inharmonicity = 0.00005 * (frequency / 1000.0)  # é™ä½ä¸€åŠ

    # ä½é€šæ»¤æ³¢å™¨ç³»æ•°ï¼ˆæ¨¡æ‹Ÿå¼¦çš„é˜»å°¼ï¼‰- æé«˜ç³»æ•°ï¼Œä¿ç•™æ›´å¤šé«˜é¢‘
    damping_coef = 0.6 + (frequency / 4186.0) * 0.35  # æé«˜åŸºç¡€å€¼

    # Karplus-Strong ä¸»å¾ªç¯
    for i in range(delay_samples, n_samples):
        # è¯»å–å»¶è¿Ÿçº¿
        s1 = output[i - delay_samples]
        s2 = output[i - delay_samples - 1] if i > delay_samples else 0.0

        # ä½é€šæ»¤æ³¢ï¼ˆèƒ½é‡å®ˆæ’ï¼‰
        filtered = s1 * damping_coef + s2 * (1.0 - damping_coef)

        # éè°æ³¢æˆåˆ†ï¼ˆé’¢ç´çš„é‡‘å±è´¨æ„Ÿï¼‰
        # æ·»åŠ è½»å¾®çš„é¢‘ç‡è°ƒåˆ¶
        if i % (delay_samples * 2) == 0:
            filtered *= (1.0 - inharmonicity)

        # åº”ç”¨è¡°å‡
        output[i] = filtered * base_decay

    return output


@jit(nopython=True, fastmath=True)
def soundboard_resonance(signal, frequency):
    """
    éŸ³æ¿å…±é¸£æ¨¡æ‹Ÿï¼ˆç®€åŒ–çš„æ¨¡æ€åˆæˆï¼‰

    é’¢ç´éŸ³æ¿çš„ç‰¹ç‚¹ï¼š
    1. æœ‰å¤šä¸ªå…±æŒ¯å³°ï¼ˆæ¨¡æ€ï¼‰
    2. ä½é¢‘å…±æŒ¯å³°åœ¨ 100-200Hz
    3. ä¸­é¢‘å…±æŒ¯å³°åœ¨ 400-600Hz
    """
    n = len(signal)
    output = np.zeros(n, dtype=np.float32)

    # ä¸»å…±æŒ¯å³°ï¼ˆæ ¹æ®éŸ³ç¬¦é¢‘ç‡è°ƒæ•´ï¼‰
    resonance_freq = frequency * 0.93

    # äºŒé˜¶å…±æŒ¯æ»¤æ³¢å™¨å‚æ•°
    w = 2.0 * np.pi * resonance_freq / SR
    r = 0.98  # Q å€¼

    # çŠ¶æ€å˜é‡
    y1, y2 = 0.0, 0.0

    for i in range(n):
        # IIR äºŒé˜¶å…±æŒ¯å™¨
        y0 = signal[i] + 2.0 * r * np.cos(w) * y1 - r * r * y2
        output[i] = y0
        y2 = y1
        y1 = y0

    return output


def sympathetic_resonance(mix_buffer, events):
    """
    æ³›éŸ³å…±é¸£ï¼ˆSympathetic Resonanceï¼‰

    é’¢ç´çš„ä¸€ä¸ªé‡è¦ç‰¹æ€§ï¼šå½“æŒ‰ä¸‹ä¸€ä¸ªé”®æ—¶ï¼Œå…¶æ³›éŸ³å¯¹åº”çš„å…¶ä»–å¼¦
    ä¹Ÿä¼šè½»å¾®æŒ¯åŠ¨ï¼ˆå³ä½¿æ²¡æœ‰è¢«å‡»æ‰“ï¼‰
    """
    # ç®€åŒ–å®ç°ï¼šå¯¹æ¯ä¸ªéŸ³ç¬¦ï¼Œæ¿€å‘å…¶å…«åº¦éŸ³çš„è½»å¾®å…±é¸£
    # è¿™é‡Œæš‚æ—¶è·³è¿‡ï¼Œç•™ç»™æœªæ¥ä¼˜åŒ–
    return mix_buffer


def piano_eq_mastering(audio_buffer):
    """
    é’¢ç´ä¸“ç”¨æ¯å¸¦ EQï¼ˆæ˜äº®ç‰ˆæœ¬ï¼‰

    ç›®æ ‡ï¼š
    1. ä¿ç•™ä½é¢‘ä¸°æ»¡æ„Ÿ
    2. å¤§å¹…æå‡é«˜é¢‘æ˜äº®åº¦ï¼ˆè§£å†³é—·éŸ³ï¼‰
    3. å‰Šå‡ä¸­é¢‘"æœ¨å¤´å‘³"
    """
    # 1. æ¸©å’Œçš„é«˜é€šï¼ˆåªåˆ‡æä½é¢‘ 25Hzï¼‰
    sos_hp = signal.butter(2, 25, 'hp', fs=SR, output='sos')
    audio_buffer = signal.sosfilt(sos_hp, audio_buffer)

    # 2. ä½é¢‘è½»å¾®æå‡ï¼ˆ80-150Hzï¼Œæ¸©æš–æ„Ÿï¼‰
    b_low, a_low = signal.iirpeak(110, 8, SR)
    low_boost = signal.lfilter(b_low, a_low, audio_buffer) * 0.1
    audio_buffer = audio_buffer + low_boost

    # 3. ä¸­é¢‘å¤§å¹…å‰Šå‡ï¼ˆ400-800Hzï¼Œæ¶ˆé™¤"é—·"æ„Ÿï¼‰
    # ä½¿ç”¨å®½å¸¦é™·æ³¢
    b_mid1, a_mid1 = signal.iirnotch(500, 15, SR)
    audio_buffer = signal.lfilter(b_mid1, a_mid1, audio_buffer)

    b_mid2, a_mid2 = signal.iirnotch(700, 15, SR)
    audio_buffer = signal.lfilter(b_mid2, a_mid2, audio_buffer)

    # 4. é«˜é¢‘å¤§å¹…æå‡ï¼ˆ2-6kHzï¼Œæ˜äº®æ„Ÿï¼‰
    # ä¸´åœºæ„Ÿé¢‘æ®µ
    b_presence, a_presence = signal.iirpeak(3000, 10, SR)
    presence_boost = signal.lfilter(b_presence, a_presence, audio_buffer) * 0.4
    audio_buffer = audio_buffer + presence_boost

    # ç©ºæ°”æ„Ÿé¢‘æ®µ
    b_air, a_air = signal.iirpeak(5000, 8, SR)
    air_boost = signal.lfilter(b_air, a_air, audio_buffer) * 0.3
    audio_buffer = audio_buffer + air_boost

    # 5. è¶…é«˜é¢‘æå‡ï¼ˆ8-12kHzï¼Œ"ç©ºæ°”æ„Ÿ"ï¼‰
    sos_shelf = signal.butter(2, 8000, 'hp', fs=SR, output='sos')
    high_shelf = signal.sosfilt(sos_shelf, audio_buffer) * 0.2
    audio_buffer = audio_buffer + high_shelf

    # 6. æœ€é«˜é¢‘æŸ”åŒ–ï¼ˆé¿å…åˆºè€³ï¼Œä½†ä¿ç•™åˆ° 15kHzï¼‰
    sos_lp = signal.butter(1, 15000, 'lp', fs=SR, output='sos')
    audio_buffer = signal.sosfilt(sos_lp, audio_buffer)

    return audio_buffer


def multiband_compressor(audio_buffer):
    """
    å¤šé¢‘æ®µå‹ç¼©å™¨ï¼ˆè½»é‡ç‰ˆï¼Œé¿å…è¿‡é—·ï¼‰

    è§£å†³é’¢ç´çš„åŠ¨æ€èŒƒå›´è¿‡å¤§é—®é¢˜ï¼š
    - ä½é¢‘ï¼šè½»å‹ç¼©ï¼ˆä¿ç•™ä¸°æ»¡æ„Ÿï¼‰
    - ä¸­é¢‘ï¼šè½»å‹ç¼©ï¼ˆé¿å…é—·ï¼‰
    - é«˜é¢‘ï¼šå‡ ä¹ä¸å‹ç¼©ï¼ˆä¿æŒæ˜äº®ï¼‰
    """
    # åˆ†é¢‘ç‚¹
    low_freq = 250
    high_freq = 2000

    # ä½é¢‘æ®µ
    sos_low = signal.butter(4, low_freq, 'lp', fs=SR, output='sos')
    low_band = signal.sosfilt(sos_low, audio_buffer)

    # é«˜é¢‘æ®µ
    sos_high = signal.butter(4, high_freq, 'hp', fs=SR, output='sos')
    high_band = signal.sosfilt(sos_high, audio_buffer)

    # ä¸­é¢‘æ®µ
    mid_band = audio_buffer - low_band - high_band

    # åˆ†åˆ«å‹ç¼©ï¼ˆå¤§å¹…å‡è½»å‹ç¼©å¼ºåº¦ï¼‰
    low_band = np.tanh(low_band * 1.1) / 1.1  # æè½»å‹ç¼©
    mid_band = np.tanh(mid_band * 1.15) / 1.15  # æè½»å‹ç¼©
    high_band = high_band * 1.05  # å‡ ä¹ä¸å‹ç¼©ï¼Œåè€Œè½»å¾®æå‡

    # æ··åˆ
    return low_band + mid_band + high_band


def midi_to_audio(midi_stream, brightness, pluck_pos, body_mix, reflection, coupling):
    try:
        mid = mido.MidiFile(file=midi_stream)
    except Exception as e:
        print(f"MIDI è§£æå¤±è´¥: {e}")
        return None, None

    # é¢„è®¡ç®—æ€»æ—¶é•¿
    total_len = sum(msg.time for msg in mid) + 5.0  # é’¢ç´ä½™éŸ³æ›´é•¿
    total_samples = int(total_len * SR)
    if total_samples > SR * 300:
        total_samples = SR * 300

    mix_buffer = np.zeros(total_samples, dtype=np.float32)

    # === MIDI äº‹ä»¶è§£æï¼ˆæ”¯æŒå»¶éŸ³è¸æ¿ï¼‰ ===
    events = []
    cursor = 0
    sustain_pedal = False
    active_notes = {}

    for msg in mid:
        cursor += int(msg.time * SR)

        # å»¶éŸ³è¸æ¿
        if msg.type == 'control_change' and msg.control == 64:
            sustain_pedal = (msg.value >= 64)

        elif msg.type == 'note_on' and msg.velocity > 0:
            active_notes[msg.note] = (cursor, msg.velocity, sustain_pedal)

        elif (msg.type == 'note_off') or (msg.type == 'note_on' and msg.velocity == 0):
            if msg.note in active_notes:
                start, vel, pedaled = active_notes.pop(msg.note)
                events.append((start, cursor, msg.note, vel, pedaled))

    # æœªå…³é—­çš„éŸ³ç¬¦
    for note, (start, vel, pedaled) in active_notes.items():
        events.append((start, total_samples - SR * 2, note, vel, pedaled))

    print(f"ğŸ¹ é’¢ç´å¼•æ“ï¼šå¤„ç† {len(events)} ä¸ªéŸ³ç¬¦äº‹ä»¶")

    # === è‡ªåŠ¨å¢ç›Šæ§åˆ¶ ===
    max_polyphony = 1
    time_grid = np.zeros(total_samples, dtype=np.int16)
    for start, end, note, vel, pedal in events:
        if start < total_samples and end > start:
            end = min(end, total_samples)
            time_grid[start:end] += 1
            max_polyphony = max(max_polyphony, np.max(time_grid[start:end]))

    # === è‡ªåŠ¨å¢ç›Šæ§åˆ¶ (ä¼˜åŒ–ç‰ˆï¼šä¸å†è¿‡åº¦æƒ©ç½š) ===
    # é’¢ç´ä¸éœ€è¦åƒå‰ä»–é‚£æ ·æ¿€è¿›çš„ AGCï¼Œå›ºå®šä¸€ä¸ªåŸºç¡€å¢ç›Šï¼Œæœ€åé  Normalization è¡¥é½
    agc_factor = 0.8  # æé«˜åŸºç¡€å¢ç›Š

    # === éŸ³ç¬¦æ¸²æŸ“ ===
    for start, end, note, velocity, pedaled in events:
        if start >= total_samples:
            continue

        freq = 440.0 * (2.0 ** ((note - 69) / 12.0))
        if freq > SR / 2 or freq < 27.5:
            continue

        # å†³å®šå¼¦æ•°
        if note < 30: num_strings = 1
        elif note < 50: num_strings = 2
        else: num_strings = 3

        # === çº¿æ€§åŠ›åº¦å“åº” (ä¸å†ä½¿ç”¨é«˜æ¬¡æ–¹) ===
        vel_curve = (velocity / 127.0) ** 1.2 
        final_velocity = vel_curve * agc_factor

        # æ¸²æŸ“
        string_outputs = []
        for s in range(num_strings):
            detune_cents = (s - num_strings / 2.0) * 0.5
            detune_ratio = 2.0 ** (detune_cents / 1200.0)
            
            # æ³¨æ„ï¼šè¿™é‡Œä¸å†å¯¹ velocity è¿›è¡Œå¤šé‡é™¤æ³•
            string_wave = piano_string_model(
                min(int(SR * 6.0), total_samples - start),
                freq * detune_ratio,
                final_velocity, 
                s,
                num_strings
            )
            string_outputs.append(string_wave)

        # æ··åˆå¤šæ ¹å¼¦ï¼šä½¿ç”¨å‡å€¼è€ŒéäºŒæ¬¡æ±‚å’Œé™¤æ³•
        combined = np.mean(np.array(string_outputs), axis=0) if num_strings > 1 else string_outputs[0]

        # éŸ³æ¿å…±é¸£
        resonance = soundboard_resonance(combined, freq)
        final_wave = combined * 0.6 + resonance * 0.4
        

        # === åŒ…ç»œï¼ˆåˆ¶éŸ³å™¨ï¼‰ ===
        if not pedaled:
            # æ¨¡æ‹Ÿåˆ¶éŸ³å™¨çš„å¿«é€Ÿè¡°å‡
            damper_time = int(SR * 0.2)
            note_off = end - start

            if 0 < note_off < len(final_wave) - damper_time:
                fade = np.exp(-np.linspace(0, 5, damper_time))
                final_wave[note_off:note_off + damper_time] *= fade
                final_wave[note_off + damper_time:] = 0.0

        # å åŠ åˆ°æ··éŸ³
        end_idx = min(start + len(final_wave), total_samples)
        mix_buffer[start:end_idx] += final_wave[:end_idx - start]

    # === åå¤„ç†é“¾ ===
    print("   åº”ç”¨åå¤„ç†...")

    # 1. é’¢ç´ä¸“ç”¨ EQ
    mix_buffer = piano_eq_mastering(mix_buffer)

    # 2. å¤šé¢‘æ®µå‹ç¼©
    mix_buffer = multiband_compressor(mix_buffer)

    # 3. éŸ³ä¹å…æ··å“
    if reflection > 0.01:
        # é’¢ç´éœ€è¦æ›´é•¿çš„æ··å“
        delays = [
            int(SR * 0.04),  # æ—©æœŸåå°„
            int(SR * 0.09),  # ä¸­æœŸ
            int(SR * 0.15),  # åæœŸ
            int(SR * 0.23)  # å°¾éƒ¨
        ]
        decays = [0.6, 0.4, 0.25, 0.15]

        reverb = np.zeros_like(mix_buffer)
        for delay, decay in zip(delays, decays):
            if len(mix_buffer) > delay:
                reverb[delay:] += mix_buffer[:-delay] * reflection * decay

        mix_buffer = mix_buffer * 0.75 + reverb * 0.25

    # 4. æœ€ç»ˆé™åˆ¶
    peak = np.max(np.abs(mix_buffer))
    if peak > 0.0001:
        mix_buffer = mix_buffer / peak * 0.9

    # è½¬æ¢ä¸º WAV
    samples_int = (mix_buffer * 32767).astype(np.int16)

    buf = io.BytesIO()
    try:
        with wave.open(buf, 'wb') as wf:
            wf.setnchannels(1)
            wf.setsampwidth(2)
            wf.setframerate(SR)
            wf.writeframes(samples_int.tobytes())
    except Exception as e:
        print(f"WAV å†™å…¥å¤±è´¥: {e}")
        return None, None

    print("âœ… é’¢ç´æ¸²æŸ“å®Œæˆ")
    return buf.getvalue(), mix_buffer

